/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package edu.columbia.incite.analysis.index;

import java.io.IOException;
import java.util.Collection;
import java.util.Iterator;

import org.apache.lucene.analysis.TokenStream;
import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
import org.apache.lucene.util.BytesRef;
import org.apache.uima.cas.text.AnnotationFS;


/**
 * TokenStream implementation for UIMA annotations.
 * 
 * This class adds the @link{UIMATokenStream.setInput} method to Lucene's standard 
 * @link{TokenStream}'s contract.
 * 
 * This method should be called immediately before supplying a document containing an indexed field 
 * using this TokenStream to a Lucene tokenstream consumer (i.e. typically an IndexWriter), after 
 * which this stream will be exhausted until @link{setInput} is called again.
 * 
 * Takes a (sorted) Collection of UIMA annotations and an offset corresponding to the beginning of 
 * the associated document in the source CAS's SOFA string.
 * 
 * The order of generated tokens in the resulting token stream will be give by the order of 
 * iteration of the supplied collection, allowing for custom sorting of tokens, if such a thing 
 * were ever reasonable. I.e. in virtually all cases the collections will be lists with a fixed 
 * iteration order, but who am I to speculate on downstream's needs.
 * 
 * The given offset will be substracted from each annotation in the given collections's begin and 
 * end annotation in order to allow for multi-document CASes to be indexed correctly. E.g. when 
 * indexing a CAS containings a segmentation into paragraphs, the offset should correspond to each 
 * paragraphs begin position in the source CAS, in order to ensure that the tokens generated by 
 * this stream have the correct offset into the paragraph, which is then submitted to Lucene as a 
 * "document".
 * 
 * Failure to pass correct offsets will break all of Lucene's positional search facilities and 
 * create who knows what additional what havok further down the indexing chain.
 * 
 * @author José Tomás Atria <jtatria at gmail.com>
 */
class UIMATokenStream extends TokenStream {
    // Input data
    private Collection<AnnotationFS> src;
    private Integer offset;

    // State data
    private Iterator<AnnotationFS> annIt;
    private AnnotationFS cur;
    private Integer last = 0;

    private final Tokenizer tokenizer;

    private final OffsetAttribute   osAttr;
    private final CharTermAttribute ctAttr;
    private final PayloadAttribute  plAttr;
    private final TypeAttribute     tyAttr;

    /**
     * Create a new UIMATokenStream with the given Tokenizer.
     * 
     * Instances of this class can be reused across documents.
     * 
     * @param tn 
     */
    UIMATokenStream( Tokenizer tn ) {
        this.tokenizer = tn;
        this.osAttr = addAttribute( OffsetAttribute.class );
        this.ctAttr = addAttribute( CharTermAttribute.class );
        this.plAttr = addAttribute( PayloadAttribute.class );
        this.tyAttr = addAttribute( TypeAttribute.class );
    }

    /**
     * This method should be called before passing a document containing a field containing this
     * TokenStream to a consumer in order to prepare it for consumption.
     * 
     * Failure to do so will result in an IOException when consumers attempt to call this 
     * TokenStream's @link{TokenStream.reset} method.
     * 
     * @param anns      A @link{Collection} with the UIMA annotations for this field in the current 
     * document.
     * @param offset    The current document's offset into the source CAS's SOFA string.
     * 
     * @return This UIMATokenStream, ready to be added to a document's field before passing the 
     *         containing document to a consumer.
     */
    UIMATokenStream setInput( Collection<AnnotationFS> anns, int offset ) {
        this.src = anns;
        this.offset = offset;
        return this;
    }

    @Override
    public void close() throws IOException {
        super.close();
        // Clear input.
        this.src = null;
        this.offset = null;
    }

    @Override
    public void end() throws IOException {
        super.end();
        addAttribute( OffsetAttribute.class ).setOffset( last, last );
        // Clear state.
        this.annIt = null;
        this.cur = null;
    }

    @Override
    public void reset() throws IOException {
        super.reset();
        if( src == null ) {
            throw new IllegalStateException( "No input for token stream!" );
        }
        clearAttributes();
        annIt = src.iterator();
        last = 0;
    }

    @Override
    public boolean incrementToken() throws IOException {
        clearAttributes();

        String term = Tokenizer.NOTERM;
        while( annIt.hasNext() && term.equals( "" ) ) {
            cur = annIt.next();
            term = tokenizer.charterm( cur );
            if( !term.equals( Tokenizer.NOTERM ) ) {
                
                 // TODO This is naive and needs refactoring
                last = last > cur.getEnd() ? last : cur.getEnd();
                if( last > cur.getEnd() ) {
                    addAttribute( PositionIncrementAttribute.class ).setPositionIncrement( 0 );
                }
                
                osAttr.setOffset( cur.getBegin() - offset, cur.getEnd() - offset );
                
                ctAttr.append( term );
                // TODO: reuse bytesref
                
                plAttr.setPayload( new BytesRef( tokenizer.payload( cur ) ) );
                
                tyAttr.setType( tokenizer.type( cur ) );
                
                return true;
            }
        }
        return false;
    }
}
